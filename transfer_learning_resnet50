{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/normanglad/transfer-learning-resnet50?scriptVersionId=295538948\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nFlower photos classification – fixed & optimized for P100 GPU\n\"\"\"\nimport os\nimport pathlib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import mixed_precision\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# ─── GPU / Mixed Precision Setup ────────────────────────────────────────\nprint(\"TF version:\", tf.__version__)\nprint(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n\n# Enable mixed precision → big speedup on P100\nmixed_precision.set_global_policy('mixed_float16')\nprint(\"Using mixed precision:\", mixed_precision.global_policy().name)\n\n# ─── Settings ───────────────────────────────────────────────────────────\nBATCH_SIZE = 64           # increased – good for P100 + mixed precision\nNUM_CLASSES = 5\nEPOCHS = 20\nIMG_SIZE = 224\nINPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n\n# ─── Data loading ───────────────────────────────────────────────────────\ndef load_data():\n    # Download & extract if needed\n    dataset_path = tf.keras.utils.get_file(\n        origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n        fname='flower_photos',\n        untar=True\n    )\n    \n    # VERY IMPORTANT: point to the folder that contains the 5 class subfolders\n    data_dir = pathlib.Path(dataset_path) / 'flower_photos'\n\n    datagen = ImageDataGenerator(\n        rescale=1.0 / 255,\n        validation_split=0.2,\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )\n\n    train_gen = datagen.flow_from_directory(\n        data_dir,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        subset='training',\n        class_mode='categorical'\n    )\n\n    val_gen = datagen.flow_from_directory(\n        data_dir,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        shuffle=False,               # better for evaluation\n        subset='validation',\n        class_mode='categorical'\n    )\n\n    # Get class names automatically (should be 5)\n    class_names = sorted(train_gen.class_indices.keys())\n    print(\"Detected classes:\", class_names)\n\n    return train_gen, val_gen, class_names\n\n\n# ─── Model definition ───────────────────────────────────────────────────\ndef create_model(input_shape):\n    base_model = ResNet50(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    # Important: keep final layer in float32 for numerical stability with mixed precision\n    predictions = Dense(NUM_CLASSES, activation='softmax', dtype='float32')(x)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    # Freeze most of base model (except BatchNorm layers)\n    for layer in base_model.layers:\n        if 'bn' not in layer.name.lower():\n            layer.trainable = False\n\n    model.compile(\n        optimizer=RMSprop(learning_rate=0.0001),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n\n    return model\n\n\n# ─── Main execution ─────────────────────────────────────────────────────\nif __name__ == \"__main__\":\n    train_gen, val_gen, class_names = load_data()\n\n    model = create_model(INPUT_SHAPE)\n\n    model_name = \"ResNet50_flower_finetune\"\n\n    # Callbacks\n    os.makedirs(\"results\", exist_ok=True)\n    os.makedirs(\"logs\", exist_ok=True)\n\n    checkpoint = ModelCheckpoint(\n        filepath=os.path.join(\"results\", f\"{model_name}-e{{epoch:03d}}-vl{{val_loss:.3f}}.h5\"),\n        save_best_only=True,\n        monitor=\"val_loss\",\n        mode=\"min\",\n        verbose=1\n    )\n\n    tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n\n    reduce_lr = ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=3,\n        min_lr=1e-7,\n        verbose=1\n    )\n\n    steps_train = train_gen.samples // BATCH_SIZE\n    steps_val   = val_gen.samples   // BATCH_SIZE\n\n    print(f\"Train steps: {steps_train}   |   Val steps: {steps_val}\")\n\n    # Train\n    model.fit(\n        train_gen,\n        steps_per_epoch=steps_train,\n        validation_data=val_gen,\n        validation_steps=steps_val,\n        epochs=EPOCHS,\n        verbose=1,\n        callbacks=[tensorboard, checkpoint, reduce_lr]\n    )\n\n    # ─── Evaluation & Visualization ─────────────────────────────────────\n    # Try to load best checkpoint (update filename pattern if needed)\n    best_weights = \"results/ResNet50_flower_finetune-e020-vl0.xxx.h5\"  # ← change after training\n    if os.path.exists(best_weights):\n        model.load_weights(best_weights)\n        print(f\"Loaded: {best_weights}\")\n    else:\n        print(\"Best weights not found → using final weights\")\n\n    loss, acc = model.evaluate(val_gen, verbose=1)\n    print(f\"Validation loss: {loss:.4f}\")\n    print(f\"Validation acc : {acc:.4f}\")\n\n    # Show predictions\n    images, labels = next(iter(val_gen))\n    preds = model.predict(images, verbose=0)\n\n    true_idx  = np.argmax(labels, axis=1)\n    pred_idx  = np.argmax(preds, axis=1)\n\n    true_names = [class_names[i] for i in true_idx]\n    pred_names = [class_names[i] for i in pred_idx]\n\n    plt.figure(figsize=(12, 10))\n    for i in range(min(30, len(images))):\n        plt.subplot(6, 5, i + 1)\n        plt.imshow(images[i])\n        title = pred_names[i].title()\n        color = 'blue' if pred_names[i] == true_names[i] else 'red'\n        if pred_names[i] != true_names[i]:\n            title += f\"\\n(true: {true_names[i]})\"\n        plt.title(title, color=color, fontsize=9)\n        plt.axis('off')\n\n    plt.suptitle(\"Predictions – blue = correct, red = wrong\")\n    plt.tight_layout()\n    plt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T20:46:49.316691Z","iopub.execute_input":"2026-02-02T20:46:49.317025Z","iopub.status.idle":"2026-02-02T20:59:18.881967Z","shell.execute_reply.started":"2026-02-02T20:46:49.316996Z","shell.execute_reply":"2026-02-02T20:59:18.88069Z"}},"outputs":[],"execution_count":null}]}